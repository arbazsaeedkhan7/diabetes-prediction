{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source: Pima Indians Diabetes Database\n",
    "## TASK: Predict the probability of diabetes occurrence based on diagnostic measures.\n",
    "## **First, Importing all necessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For Data Cleaning\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# For Data Splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For Data Preprocessing\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# For Model Building\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# For Model Evaluation\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, mean_squared_error\n",
    "from sklearn import metrics\n",
    "\n",
    "# For Model Tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetesDF = pd.read_csv('diabetes.csv')\n",
    "diabetesDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the data distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetesDF.hist(figsize=(15,12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Description of the dataset</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetesDF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetesDF.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Interpretation</h3>\n",
    "1. Pregnancies: Women in this dataset have an average of 3.85 pregnancies, with a range from 0 to 17.<br>\n",
    "2. Glucose: The average glucose level is 120.89, with values ranging from 0 to 199. The presence of 0 values might indicate missing data.<br>\n",
    "3. Blood Pressure: Average blood pressure is 69.11, with a range from 0 to 122. Similar to glucose, 0 values could indicate missing data.<br>\n",
    "4. Skin Thickness: The average skin thickness is 20.54, with many 0 values indicating possible missing data.<br>\n",
    "5. Insulin: Insulin levels vary widely (mean 79.80, std 115.24), with many 0 values, suggesting a lot of missing or unrecorded data.<br>\n",
    "6. BMI: The average BMI is 31.99, which is in the overweight range, with values up to 67.1.<br>\n",
    "7. Diabetes Pedigree Function: This variable measures genetic influence, with an average value of 0.47.<br>\n",
    "8. Age: The average age is 33.24, ranging from 21 to 81, indicating a relatively young to middle-aged population.<br>\n",
    "9. Outcome: About 34.9% of individuals have diabetes (mean outcome of 0.35).<br>\n",
    "\n",
    "but........<br><br>\n",
    "On the columns below, a value of zero does not make sense and thus indicates missing value;<br><br>\n",
    "Glucose<br>\n",
    "BloodPressure<br>\n",
    "SkinThickness<br>\n",
    "Insulin<br>\n",
    "BMI<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing zeros with NaN (so that counting and manipulating them is easier)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetesDF_copy = diabetesDF.copy(deep = True)\n",
    "diabetesDF_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = diabetesDF_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRINTING THE NUMER OF MISSING VALUES IN EACH COLUMN\n",
    "diabetesDF_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the KNN Imputer instead of simple mean or median imputation methods because it leverages the relationships between features by considering the k-nearest neighbors, leading to more accurate and appropriate imputations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "diabetesDF_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = knn_imputer.fit_transform(diabetesDF_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetesDF_copy.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['Glucose','BloodPressure','Insulin','Age','Outcome','BMI']\n",
    "\n",
    "sns.pairplot(diabetesDF_copy[col] ,hue='Outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = diabetesDF_copy.corr()\n",
    "sns.heatmap(corr, \n",
    "         xticklabels=corr.columns, \n",
    "         yticklabels=corr.columns,\n",
    "         annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='BMI', y= 'Glucose', data=diabetesDF_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='Glucose', y= 'Insulin', data=diabetesDF_copy, hue='Outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=diabetesDF_copy, x='Insulin',hue='Outcome' ,fill=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Outliers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in diabetesDF_copy:\n",
    "    \n",
    "    Q1 = diabetesDF_copy[feature].quantile(0.25)\n",
    "    Q3 = diabetesDF_copy[feature].quantile(0.75)\n",
    "    IQR = Q3-Q1\n",
    "    lower = Q1- 1.5*IQR\n",
    "    upper = Q3 + 1.5*IQR\n",
    "    \n",
    "    if diabetesDF_copy[(diabetesDF_copy[feature] > upper)].any(axis=None):\n",
    "        print(feature,\"yes\")\n",
    "    else:\n",
    "        print(feature, \"no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting boxplots to visualize outliers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,10))\n",
    "sns.set_style(style='whitegrid')\n",
    "\n",
    "plt.subplot(2,3,1)\n",
    "sns.boxplot(x='BloodPressure',data=diabetesDF_copy)\n",
    "plt.subplot(2,3,2)\n",
    "sns.boxplot(x='Insulin',data=diabetesDF_copy)\n",
    "plt.subplot(2,3,3)\n",
    "sns.boxplot(x='BMI',data=diabetesDF_copy)\n",
    "plt.subplot(2,3,4)\n",
    "sns.boxplot(x='Age',data=diabetesDF_copy)\n",
    "plt.subplot(2,3,5)\n",
    "sns.boxplot(x='SkinThickness',data=diabetesDF_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='Outcome',y='Insulin',data=diabetesDF_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting outliers using Local Outlier Factor (LOF)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lof =LocalOutlierFactor(n_neighbors= 10)\n",
    "lof.fit_predict(diabetesDF_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = lof.negative_outlier_factor_\n",
    "print(np.sort(df_scores)[0:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting a threshold for outliers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.sort(df_scores)[7]\n",
    "threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing all outliers based on set threshold..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier = df_scores > threshold\n",
    "diabetesDF_cleaned = diabetesDF_copy[outlier]\n",
    "diabetesDF_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data into target and features..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = diabetesDF_cleaned['Outcome']\n",
    "X = diabetesDF_cleaned.drop('Outcome', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data into training and testing data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation and Hyperparameter Tuning\n",
    "\n",
    "**Defining models and param grids**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models and their parameter grids\n",
    "models = {\n",
    "    'Decision Tree': (DecisionTreeClassifier(random_state=90), {\n",
    "        'classifier__max_depth': [None, 5, 10, 15]\n",
    "    }),\n",
    "    'Random Forest': (RandomForestClassifier(random_state=42), {\n",
    "        'classifier__n_estimators': [50, 80, 100],\n",
    "        'classifier__max_depth': [None, 10, 20, 30]\n",
    "    }),\n",
    "    'K-Nearest Neighbors': (KNeighborsClassifier(), {\n",
    "        'classifier__n_neighbors': [3, 5, 7, 9]\n",
    "    }),\n",
    "    'Logistic Regression': (LogisticRegression(random_state=90), {\n",
    "        'classifier__C': [0.01, 0.1, 1, 10, 100]\n",
    "    })\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining function to create a pipeline to: perform grid search & evaluate the model's performance using cross-validation,**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create pipeline, perform grid search, and evaluate model\n",
    "def train_and_evaluate_with_grid_search(model, param_grid, X_train, y_train, X_test, y_test):\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('smote', SMOTE(random_state=99)),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Evaluate on the test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    print(f\"Best parameters for {model}: {best_params}\")\n",
    "    print(f\"Best cross-validation score for {model}: {best_score}\")\n",
    "    print(\"Test Accuracy:\", accuracy)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cnf_matrix, annot=True, fmt='g')\n",
    "    plt.title('Confusion matrix', y=1.1)\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "    \n",
    "    return accuracy, f1, best_params\n",
    "\n",
    "\n",
    "\n",
    "# Store results for comparison\n",
    "results = []\n",
    "\n",
    "for model_name, (model, param_grid) in models.items():\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    accuracy, f1, best_params = train_and_evaluate_with_grid_search(model, param_grid, X_train, y_train, X_test, y_test)\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Best Parameters': best_params,\n",
    "        'Test Accuracy': accuracy,\n",
    "        'F1 Score': f1\n",
    "    })\n",
    "\n",
    "# Create a DataFrame to summarize results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Importance Analysis for RandomForestClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the selected model on the entire dataset\n",
    "best_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = best_model.feature_importances_\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print feature importances\n",
    "for i, feature_index in enumerate(indices):\n",
    "    print(f\"{i+1}. {X.columns[feature_index]}: {importances[feature_index]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), X.columns[indices], rotation=90)\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Importance Analysis for DecisionTreeClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Decision Tree model on the entire dataset\n",
    "decision_tree_model = DecisionTreeClassifier(max_depth=5, random_state=90)\n",
    "decision_tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances_dt = decision_tree_model.feature_importances_\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "indices_dt = np.argsort(importances_dt)[::-1]\n",
    "\n",
    "# Print feature importances\n",
    "for i, feature_index in enumerate(indices_dt):\n",
    "    print(f\"{i+1}. {X.columns[feature_index]}: {importances_dt[feature_index]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importances for Decision Tree\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Feature Importances (Decision Tree)\")\n",
    "plt.bar(range(X.shape[1]), importances_dt[indices_dt], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), X.columns[indices_dt], rotation=90)\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Importance Analysis for LogisticRegression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_balanced)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fit Logistic Regression model on the entire dataset\n",
    "logistic_regression_model = LogisticRegression(random_state=90)\n",
    "logistic_regression_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Get feature coefficients\n",
    "coefficients = logistic_regression_model.coef_[0]\n",
    "\n",
    "# Sort feature coefficients in descending order\n",
    "indices_lr = np.argsort(np.abs(coefficients))[::-1]\n",
    "\n",
    "# Print feature coefficients\n",
    "for i, feature_index in enumerate(indices_lr):\n",
    "    print(f\"{i+1}. {X.columns[feature_index]}: {coefficients[feature_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature coefficients for Logistic Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Feature Coefficients (Logistic Regression)\")\n",
    "plt.bar(range(X.shape[1]), np.abs(coefficients[indices_lr]), align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), X.columns[indices_lr], rotation=90)\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Coefficient (Absolute Value)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
